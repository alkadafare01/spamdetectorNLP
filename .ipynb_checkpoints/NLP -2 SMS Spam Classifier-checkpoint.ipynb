{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing 2 - Addtional Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links -\n",
    "1. CountVector Function Details - https://kavita-ganesan.com/how-to-use-countvectorizer/#.Xr5vkmgzY2w\n",
    "2. Text PreProcessing Step - https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n",
    "3. Word Clouds - https://www.datacamp.com/community/tutorials/wordcloud-python\n",
    "4. Naive Bayes - https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "5. NB for NLP - https://towardsdatascience.com/implementing-a-naive-bayes-classifier-for-text-categorization-in-five-steps-f9192cdd54c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from dataset\n",
    "data = pd.read_csv('data/SMSSpamCollection', sep='\\t' , names=['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual  EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['msgLen']=data.message.apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='spam'].msgLen.plot(bins=50,kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data['label']=='ham'].msgLen.plot(bins=50,kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='spam'].msgLen.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='spam'].msgLen.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='spam'].msgLen.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='ham'].msgLen.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='ham'].msgLen.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['label']=='ham'].msgLen.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('label').msgLen.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPreprocessing(data):\n",
    "    #Remove Punctuation Logic\n",
    "    import string\n",
    "    removePunctuation = [char for char in data if char not in string.punctuation]\n",
    "    \n",
    "    #Join Chars to form sentences\n",
    "    sentenceWithoutPunctuations = ''.join(removePunctuation)\n",
    "    sentence = sentenceWithoutPunctuations.split()\n",
    "    \n",
    "    #StopwordRemoval\n",
    "    from nltk.corpus import stopwords\n",
    "    removeStopwords = [word for word in sentence if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return removeStopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "data['message'].head().apply(textPreprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag of Words - sklearn package CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?CountVectorizer\n",
    "#1. lowercases your text (set lowercase=false if you don’t want lowercasing)\n",
    "#2. performs tokenization (converts raw text to smaller units of text)\n",
    "#3. uses word level tokenization (meaning each word is treated as a separate token)\n",
    "#4. ignores single characters during tokenization (say goodbye to words like ‘a’ and ‘I’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(analyzer=textPreprocessing,min_df=3).fit(data['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show resulting vocabulary; the numbers are not counts, they are the position in the sparse vector.\n",
    "bow.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bow.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_bow = bow.transform(data['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "message_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(message_bow.toarray()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working With N-Grams - Word level – bigrams only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bow2gram = CountVectorizer(min_df=3,ngram_range=(2,2)).fit(data['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow2gram.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bow.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud - https://www.datacamp.com/community/tutorials/wordcloud-python\n",
    "## conda install -c conda-forge wordcloud\n",
    "## conda update --all\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=200,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_wordcloud()\n",
    "show_wordcloud(data[data['label']=='spam'].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(data[data['label']=='ham'].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfData = TfidfTransformer(use_idf=False).fit(message_bow)\n",
    "tfidfDataFinal = tfidfData.transform(message_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfData = TfidfTransformer(use_idf=True).fit(message_bow)\n",
    "tfidfDataFinal = tfidfData.transform(message_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidfData.idf_[bow.vocabulary_['WINNER']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDataFinal.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(tfidfDataFinal.toarray()).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is ready to be supplied in a machine learning algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model --- NaiveBayes Algo\n",
    "#Handling String data ---- MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(tfidfDataFinal,data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPred=model.predict(tfidfDataFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['label'],trainPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = 'Win Lottery Guaranteed'\n",
    "l1 = textPreprocessing(inputData)\n",
    "l2 = bow.transform(l1)\n",
    "l3 = tfidfData.transform(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_proba(l3[0])\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
